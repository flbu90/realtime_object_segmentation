{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing des Models in Echtzeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version updated: 12.08.2019 (latest version)\n",
    "\n",
    "ToDO:\n",
    "\n",
    "Colorize the Segments before appending to scene -->Done\n",
    "\n",
    "project points to camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyntcloud import PyntCloud\n",
    "import os\n",
    "import numpy as np\n",
    "from random import randint, uniform\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import math\n",
    "import time\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Visualize the test data\n",
    "import scipy.io as io\n",
    "import scipy.ndimage as nd\n",
    "from scipy.spatial import cKDTree\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "# Restore the trained model\n",
    "model = tf.keras.models.load_model('savedmodel/k_model_Washington.h5')\n",
    "\n",
    "# Variables\n",
    "disparity_shift = 96\n",
    "\n",
    "\n",
    "# ||||||||||||||||||||||||||||||||||||||||||||||||||||  Functions ||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "\n",
    "\n",
    "class AppState:\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.WIN_NAME = 'RealSense'\n",
    "        self.pitch, self.yaw = math.radians(-10), math.radians(-15)\n",
    "        self.translation = np.array([0, 0, -1], dtype=np.float32)\n",
    "        self.distance = 2\n",
    "        self.prev_mouse = 0, 0\n",
    "        self.mouse_btns = [False, False, False]\n",
    "        self.paused = False\n",
    "        self.decimate = 0\n",
    "        self.scale = True\n",
    "        self.color = True\n",
    "        self.spatial = False\n",
    "        self.holefilling = False\n",
    "        self.segmentation = False\n",
    "        self.minthreshold = 0.2\n",
    "        self.maxthreshold = 0.8\n",
    "        self.threshold = False\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self.pitch, self.yaw, self.distance = 0, 0, 2\n",
    "        self.translation[:] = 0, 0, -1\n",
    "\n",
    "    @property\n",
    "    def rotation(self):\n",
    "        Rx, _ = cv2.Rodrigues((self.pitch, 0, 0))\n",
    "        Ry, _ = cv2.Rodrigues((0, self.yaw, 0))\n",
    "        return np.dot(Ry, Rx).astype(np.float32)\n",
    "\n",
    "    @property\n",
    "    def pivot(self):\n",
    "        return self.translation + np.array((0, 0, self.distance), dtype=np.float32)\n",
    "    \n",
    "\n",
    "def mouse_cb(event, x, y, flags, param):\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        state.mouse_btns[0] = True\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        state.mouse_btns[0] = False\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        state.mouse_btns[1] = True\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONUP:\n",
    "        state.mouse_btns[1] = False\n",
    "\n",
    "    if event == cv2.EVENT_MBUTTONDOWN:\n",
    "        state.mouse_btns[2] = True\n",
    "\n",
    "    if event == cv2.EVENT_MBUTTONUP:\n",
    "        state.mouse_btns[2] = False\n",
    "\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "\n",
    "        h, w = out.shape[:2]\n",
    "        dx, dy = x - state.prev_mouse[0], y - state.prev_mouse[1]\n",
    "\n",
    "        if state.mouse_btns[0]:\n",
    "            state.yaw += float(dx) / w * 2\n",
    "            state.pitch -= float(dy) / h * 2\n",
    "\n",
    "        elif state.mouse_btns[1]:\n",
    "            dp = np.array((dx / w, dy / h, 0), dtype=np.float32)\n",
    "            state.translation -= np.dot(state.rotation, dp)\n",
    "\n",
    "        elif state.mouse_btns[2]:\n",
    "            dz = math.sqrt(dx**2 + dy**2) * math.copysign(0.01, -dy)\n",
    "            state.translation[2] += dz\n",
    "            state.distance -= dz\n",
    "\n",
    "    if event == cv2.EVENT_MOUSEWHEEL:\n",
    "        dz = math.copysign(0.1, flags)\n",
    "        state.translation[2] += dz\n",
    "        state.distance -= dz\n",
    "\n",
    "    state.prev_mouse = (x, y)\n",
    "    \n",
    "    \n",
    "\n",
    "def project(v):\n",
    "    \"\"\"project 3d vector array to 2d\"\"\"\n",
    "    h, w = out.shape[:2]\n",
    "    view_aspect = float(h)/w\n",
    "\n",
    "    # ignore divide by zero for invalid depth\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        proj = v[:, :-1] / v[:, -1, np.newaxis] * \\\n",
    "            (w*view_aspect, h) + (w/2.0, h/2.0)\n",
    "\n",
    "    # near clipping\n",
    "    znear = 0.03\n",
    "    proj[v[:, 2] < znear] = np.nan\n",
    "    return proj\n",
    "\n",
    "\n",
    "\n",
    "def view(v):\n",
    "    \"\"\"apply view transformation on vector array\"\"\"\n",
    "    return np.dot(v - state.pivot, state.rotation) + state.pivot - state.translation\n",
    "\n",
    "\n",
    "\n",
    "def line3d(out, pt1, pt2, color=(0x80, 0x80, 0x80), thickness=1):\n",
    "    \"\"\"draw a 3d line from pt1 to pt2\"\"\"\n",
    "    p0 = project(pt1.reshape(-1, 3))[0]\n",
    "    p1 = project(pt2.reshape(-1, 3))[0]\n",
    "    if np.isnan(p0).any() or np.isnan(p1).any():\n",
    "        return\n",
    "    p0 = tuple(p0.astype(int))\n",
    "    p1 = tuple(p1.astype(int))\n",
    "    rect = (0, 0, out.shape[1], out.shape[0])\n",
    "    inside, p0, p1 = cv2.clipLine(rect, p0, p1)\n",
    "    if inside:\n",
    "        cv2.line(out, p0, p1, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        \n",
    "\n",
    "def grid(out, pos, rotation=np.eye(3), size=1, n=10, color=(0x80, 0x80, 0x80)):\n",
    "    \"\"\"draw a grid on xz plane\"\"\"\n",
    "    pos = np.array(pos)\n",
    "    s = size / float(n)\n",
    "    s2 = 0.5 * size\n",
    "    for i in range(0, n+1):\n",
    "        x = -s2 + i*s\n",
    "        line3d(out, view(pos + np.dot((x, 0, -s2), rotation)),\n",
    "               view(pos + np.dot((x, 0, s2), rotation)), color)\n",
    "    for i in range(0, n+1):\n",
    "        z = -s2 + i*s\n",
    "        line3d(out, view(pos + np.dot((-s2, 0, z), rotation)),\n",
    "               view(pos + np.dot((s2, 0, z), rotation)), color)\n",
    "\n",
    "\n",
    "        \n",
    "def axes(out, pos, rotation=np.eye(3), size=0.075, thickness=2):\n",
    "    \"\"\"draw 3d axes\"\"\"\n",
    "    line3d(out, pos, pos +\n",
    "           np.dot((0, 0, size), rotation), (0xff, 0, 0), thickness)\n",
    "    line3d(out, pos, pos +\n",
    "           np.dot((0, size, 0), rotation), (0, 0xff, 0), thickness)\n",
    "    line3d(out, pos, pos +\n",
    "           np.dot((size, 0, 0), rotation), (0, 0, 0xff), thickness)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def frustum(out, intrinsics, color=(0x40, 0x40, 0x40)):\n",
    "    \"\"\"draw camera's frustum\"\"\"\n",
    "    orig = view([0, 0, 0])\n",
    "    w, h = intrinsics.width, intrinsics.height\n",
    "\n",
    "    for d in range(1, 6, 2):\n",
    "        def get_point(x, y):\n",
    "            p = rs.rs2_deproject_pixel_to_point(intrinsics, [x, y], d)\n",
    "            line3d(out, orig, view(p), color)\n",
    "            return p\n",
    "\n",
    "        top_left = get_point(0, 0)\n",
    "        top_right = get_point(w, 0)\n",
    "        bottom_right = get_point(w, h)\n",
    "        bottom_left = get_point(0, h)\n",
    "\n",
    "        line3d(out, view(top_left), view(top_right), color)\n",
    "        line3d(out, view(top_right), view(bottom_right), color)\n",
    "        line3d(out, view(bottom_right), view(bottom_left), color)\n",
    "        line3d(out, view(bottom_left), view(top_left), color)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "def pointcloud(out, verts, texcoords, color, painter=True):\n",
    "    \"\"\"draw point cloud with optional painter's algorithm\"\"\"\n",
    "    if painter:\n",
    "        # Painter's algo, sort points from back to front\n",
    "\n",
    "        # get reverse sorted indices by z (in view-space)\n",
    "        # https://gist.github.com/stevenvo/e3dad127598842459b68\n",
    "        v = view(verts)\n",
    "        s = v[:, 2].argsort()[::-1]\n",
    "        proj = project(v[s])\n",
    "    else:\n",
    "        proj = project(view(verts))\n",
    "\n",
    "    if state.scale:\n",
    "        proj *= 0.5**state.decimate\n",
    "\n",
    "    h, w = out.shape[:2]\n",
    "\n",
    "    # proj now contains 2d image coordinates\n",
    "    j, i = proj.astype(np.uint32).T\n",
    "\n",
    "    # create a mask to ignore out-of-bound indices\n",
    "    im = (i >= 0) & (i < h)\n",
    "    jm = (j >= 0) & (j < w)\n",
    "    m = im & jm\n",
    "\n",
    "    cw, ch = color.shape[:2][::-1]\n",
    "    if painter:\n",
    "        # sort texcoord with same indices as above\n",
    "        # texcoords are [0..1] and relative to top-left pixel corner,\n",
    "        # multiply by size and add 0.5 to center\n",
    "        v, u = (texcoords[s] * (cw, ch) + 0.5).astype(np.uint32).T\n",
    "    else:\n",
    "        v, u = (texcoords * (cw, ch) + 0.5).astype(np.uint32).T\n",
    "    # clip texcoords to image\n",
    "    np.clip(u, 0, ch-1, out=u)\n",
    "    np.clip(v, 0, cw-1, out=v)\n",
    "\n",
    "    # perform uv-mapping\n",
    "    out[i[m], j[m]] = color[u[m], v[m]]\n",
    "    \n",
    "\n",
    "# Colorizes the different Clusters randomly\n",
    "def colorize_pc(number_clusterpoints):\n",
    "\n",
    "    rgb = np.zeros((number_clusterpoints, 3), dtype=int)\n",
    "\n",
    "    r = randint(0, 254)\n",
    "    g = randint(0, 254)\n",
    "    b = randint(0, 254)\n",
    "\n",
    "    rgb_temp = np.array((r,g,b))\n",
    "    rgb = np.full_like(rgb,rgb_temp)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "# Helper Function to display Inliners and Outliners after Outliner Removal\n",
    "\n",
    "def display_inlier_outlier(cloud, ind):\n",
    "    inlier_cloud = o3d.geometry.select_down_sample(cloud, ind)\n",
    "    outlier_cloud = o3d.geometry.select_down_sample(cloud, ind, invert=True)\n",
    "\n",
    "    print(\"Showing outliers (red) and inliers (gray): \")\n",
    "    outlier_cloud.paint_uniform_color([1, 0, 0])\n",
    "    inlier_cloud.paint_uniform_color([0.8, 0.8, 0.8])\n",
    "    o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])\n",
    "                    \n",
    "\n",
    "\n",
    "# ---------------------------------------------------> Camera Setup <---------------------------------------------------\n",
    "\n",
    "DS5_product_ids = [\"0AD1\", \"0AD2\", \"0AD3\", \"0AD4\", \"0AD5\", \"0AF6\", \"0AFE\", \"0AFF\", \"0B00\", \"0B01\", \"0B03\", \"0B07\",\"0B3A\"]\n",
    "\n",
    "def find_device_that_supports_advanced_mode() :\n",
    "    ctx = rs.context()\n",
    "    ds5_dev = rs.device()\n",
    "    devices = ctx.query_devices();\n",
    "    for dev in devices:\n",
    "        if dev.supports(rs.camera_info.product_id) and str(dev.get_info(rs.camera_info.product_id)) in DS5_product_ids:\n",
    "            if dev.supports(rs.camera_info.name):\n",
    "                print(\"Found device that supports advanced mode:\", dev.get_info(rs.camera_info.name))\n",
    "            return dev\n",
    "    raise Exception(\"No device that supports advanced mode was found\")\n",
    "\n",
    "dev = find_device_that_supports_advanced_mode()\n",
    "device= rs.context().query_devices()[0]\n",
    "advnc_mode = rs.rs400_advanced_mode(dev)\n",
    "depth_table_control_group = advnc_mode.get_depth_table()\n",
    "depth_table_control_group.disparityShift = disparity_shift\n",
    "print(\"Set Disparity Shift to\", disparity_shift)\n",
    "advnc_mode.set_depth_table(depth_table_control_group)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------> Camera PC Stream <---------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Mouse: \n",
    "    Drag with left button to rotate around pivot (thick small axes), \n",
    "    with right button to translate and the wheel to zoom.\n",
    "Keyboard: \n",
    "    [p]     Pause\n",
    "    [r]     Reset View\n",
    "    [d]     Cycle through decimation values\n",
    "    [z]     Toggle point scaling\n",
    "    [c]     Toggle color source\n",
    "    [s]     Save PNG (./out.png)\n",
    "    [e]     Export points to ply (./out.ply)\n",
    "    [q\\ESC] Quit\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "state = AppState()\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "# Get stream profile and camera intrinsics\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "pc = rs.pointcloud()\n",
    "\n",
    "\n",
    "# |||||||||||||||||||||||||||||||||||||||||||||| Filter Setup ||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "\n",
    "\n",
    "\n",
    "decimate = rs.decimation_filter()\n",
    "decimate.set_option(rs.option.filter_magnitude, 2 ** state.decimate)\n",
    "colorizer = rs.colorizer()\n",
    "\n",
    "# Spatial Filter\n",
    "spatial = rs.spatial_filter()\n",
    "\n",
    "#hole filling \n",
    "hole_filling = rs.hole_filling_filter()\n",
    "\n",
    "#threshold\n",
    "threshold_filter = rs.threshold_filter()\n",
    "threshold_filter.set_option(rs.option.max_distance, state.maxthreshold)\n",
    "threshold_filter.set_option(rs.option.min_distance, state.minthreshold)\n",
    "\n",
    "\n",
    "cv2.namedWindow(state.WIN_NAME, cv2.WINDOW_AUTOSIZE)\n",
    "cv2.resizeWindow(state.WIN_NAME, w, h)\n",
    "cv2.setMouseCallback(state.WIN_NAME, mouse_cb)\n",
    "\n",
    "out = np.empty((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "cluster_scene = np.zeros((0, 6), dtype=float) # Placeholder for the colorized Clusterscene (x,y,z,r,g,b)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Grab camera data\n",
    "        if not state.paused:\n",
    "            \n",
    "            # Wait for a coherent pair of frames: depth and color\n",
    "            frames = pipeline.wait_for_frames()\n",
    "\n",
    "            depth_frame = frames.get_depth_frame()\n",
    "            color_frame = frames.get_color_frame()\n",
    "\n",
    "            depth_frame = decimate.process(depth_frame)\n",
    "            depth_frame = threshold_filter.process(depth_frame)\n",
    "\n",
    "\n",
    "            # Grab new intrinsics (may be changed by decimation)\n",
    "            depth_intrinsics = rs.video_stream_profile(depth_frame.profile).get_intrinsics()\n",
    "            w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "            \n",
    "            color_intrinsics = rs.video_stream_profile(color_frame.profile).get_intrinsics()\n",
    "            \n",
    "            depth_to_color_extrin = depth_frame.profile.get_extrinsics_to(color_frame.profile)\n",
    "            color_to_depth_extrin = color_frame.profile.get_extrinsics_to(depth_frame.profile)\n",
    "\n",
    "            depth_image = np.asanyarray(depth_frame.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            depth_colormap = np.asanyarray(colorizer.colorize(depth_frame).get_data())\n",
    "            \n",
    "            \n",
    "# ||||||||||||||||||||||||||||||||||||||||||||||| Filters and more ||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "\n",
    "            \n",
    "            if state.color:\n",
    "                mapped_frame, color_source = color_frame, color_image\n",
    "            else:\n",
    "                mapped_frame, color_source = depth_frame, depth_colormap\n",
    "            \n",
    "            if state.holefilling:\n",
    "                depth_frame = hole_filling.process(depth_frame)\n",
    "            else:\n",
    "                depth_frame = frames.get_depth_frame()     \n",
    "                \n",
    "            if state.spatial:\n",
    "                spatial.set_option(rs.option.filter_magnitude, 5)\n",
    "                spatial.set_option(rs.option.filter_smooth_alpha, 1)\n",
    "                spatial.set_option(rs.option.filter_smooth_delta, 50)\n",
    "                spatial.set_option(rs.option.holes_fill, 3)\n",
    "                depth_frame = spatial.process(depth_frame)\n",
    "            else:\n",
    "                depth_frame = frames.get_depth_frame()\n",
    "           \n",
    "                \n",
    "            if state.threshold:\n",
    "                threshold_filter.set_option(rs.option.max_distance, 0.5)\n",
    "                threshold_filter.set_option(rs.option.min_distance, 0.25)\n",
    "                depth_frame = threshold_filter.process(depth_frame)\n",
    "            else:\n",
    "                depth_frame = frames.get_depth_frame()\n",
    "                depth_frame = decimate.process(depth_frame)\n",
    "\n",
    "            depth_frame = threshold_filter.process(depth_frame)       \n",
    "                \n",
    "            points = pc.calculate(depth_frame)\n",
    "            pc.map_to(mapped_frame)\n",
    "\n",
    "            # Pointcloud data to arrays\n",
    "            v, t = points.get_vertices(), points.get_texture_coordinates()\n",
    "            verts = np.asanyarray(v).view(np.float32).reshape(-1, 3)  # xyz\n",
    "            texcoords = np.asanyarray(t).view(np.float32).reshape(-1, 2)  # uv\n",
    "            \n",
    "            \n",
    "# |||||||||||||||||||||||||||||||||||||||||||||||||||| SEGMEntATION ||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "\n",
    "\n",
    "            \n",
    "            if state.segmentation:\n",
    "                \n",
    "                state.paused = True\n",
    "                \n",
    "                try:\n",
    "                    \n",
    "                    x = (verts[:, 0])*(1)\n",
    "                    y = (verts[:, 1])*(-1) # Flip for correct Camera orientation\n",
    "                    z = (verts[:, 2])*(-1)\n",
    "                    \n",
    "                    df_pointcloud = pd.DataFrame(zip(x, y, z), columns=[\"x\", \"y\", \"z\"])\n",
    "                    pointcloud = PyntCloud(df_pointcloud)\n",
    "                    \n",
    "                    initial_pointcloud = PyntCloud(df_pointcloud)\n",
    "                    \n",
    "                    #~~~~~~ Outliner Removal ~~~~~~\n",
    "                    \n",
    "                    pcd = o3d.geometry.PointCloud()\n",
    "                    pcd.points = o3d.utility.Vector3dVector(pointcloud.xyz)\n",
    "                    \n",
    "                    # Quick Downsamling for better performance\n",
    "                    uni_down_pcd = o3d.geometry.uniform_down_sample(pcd, every_k_points=50)\n",
    "                    o3d.visualization.draw_geometries([uni_down_pcd])\n",
    "                    \n",
    "                    # the higher std_ration the more agressive is the outliner removal\n",
    "                    cl, ind = o3d.geometry.statistical_outlier_removal(uni_down_pcd, nb_neighbors=1000, std_ratio=0.8)\n",
    "                    display_inlier_outlier(uni_down_pcd, ind)\n",
    "                    \n",
    "                    #back to numpy array\n",
    "                    pointcloud = np.asarray(cl.points)\n",
    "                    \n",
    "                    \n",
    "                    x = (pointcloud[:, 0])*(-1) \n",
    "                    y = (pointcloud[:, 1])*(-1)\n",
    "                    z = (pointcloud[:, 2])*(1)\n",
    "                    \n",
    "                    df_pointcloud = pd.DataFrame(zip(x, y, z), columns=[\"x\", \"y\", \"z\"])\n",
    "                    pointcloud = PyntCloud(df_pointcloud)\n",
    "                    \n",
    "                    pointcloud.plot(initial_point_size=0.005)\n",
    "                    \n",
    "                    \n",
    "                    # Additional Filtering\n",
    "                    \n",
    "                    #RANSAC plane fitting\n",
    "                    #surface = pointcloud.add_scalar_field(\"plane_fit\",n_inliers_to_stop=len(pointcloud.points))\n",
    "                    #pointcloud.plot(use_as_color=surface, cmap=\"RdYlGn\", output_name=\"surface\")\n",
    "                    # creates a boolean array\n",
    "                    #not_surface = pointcloud.points[surface] != 1\n",
    "                    #pointcloud.apply_filter(not_surface)\n",
    "                    \n",
    "                    voxelgrid_id = pointcloud.add_structure(\"voxelgrid\", n_x=128, n_y=128, n_z=128)\n",
    "                    voxelscene = pointcloud.structures[voxelgrid_id]\n",
    "                    \n",
    "\n",
    "                    #clusters_id = pointcloud.add_scalar_field(\"euclidean_clusters\", voxelgrid=voxelgrid_id)\n",
    "                    #pointcloud.plot(use_as_color=clusters_id, cmap=\"cool\")\n",
    "                    \n",
    "                    \n",
    "                    # Create binary array from Voxelscene\n",
    "                    binary_voxelscene = voxelscene.get_feature_vector(mode=\"binary\")\n",
    "\n",
    "                    # Prepare data for Network input\n",
    "                    binary_voxelscene = np.expand_dims(binary_voxelscene, axis=0)\n",
    "                    print(binary_voxelscene.shape)\n",
    "\n",
    "                    # Classification Output on Testvoxels\n",
    "                    cnn_out = model.predict(binary_voxelscene)\n",
    "\n",
    "                    cnn_prediction = np.argmax(cnn_out)\n",
    "\n",
    "                    print(\"Predicted Numbers of Objects:\", cnn_prediction)\n",
    "                    \n",
    "                    # Clustering\n",
    "                    kmeans = KMeans(n_clusters=cnn_prediction, init='k-means++')\n",
    "\n",
    "                    pointcloud = pointcloud.xyz\n",
    "\n",
    "                    kmeans = kmeans.fit(pointcloud)\n",
    "                    labels = kmeans.predict(pointcloud)\n",
    "                    centroids = kmeans.cluster_centers_\n",
    "\n",
    "                    # Create Clusterscene\n",
    "\n",
    "                    clusters_dict = {i: pointcloud[np.where(labels == i)[0]] for i in range(kmeans.n_clusters)}\n",
    "\n",
    "                    # COLORIZE the points\n",
    "\n",
    "                    i = 0\n",
    "                    for i in range(kmeans.n_clusters):\n",
    "                        cluster = clusters_dict[i]\n",
    "                        number_clusterpoints = cluster.shape[0]\n",
    "                        colorize_rgb = colorize_pc(number_clusterpoints)\n",
    "\n",
    "                        cluster = np.hstack((cluster, colorize_rgb))\n",
    "                        cluster_scene = np.append(cluster_scene, cluster, axis=0)\n",
    "\n",
    "                    x = cluster_scene[:, 0]\n",
    "                    y = cluster_scene[:, 1]\n",
    "                    z = cluster_scene[:, 2]\n",
    "\n",
    "                    red = cluster_scene[:, 3]\n",
    "                    blue = cluster_scene[:, 4]\n",
    "                    green = cluster_scene[:, 5]\n",
    "\n",
    "                    df_cluster_scene = pd.DataFrame(zip(x, y, z, red, green, blue), columns=[\"x\", \"y\", \"z\",\n",
    "                                                                                             \"red\", \"green\", \"blue\"])\n",
    "\n",
    "                    cluster_scene = PyntCloud(df_cluster_scene)\n",
    "                    print(cluster_scene)\n",
    "                    scene = cluster_scene.plot(initial_point_size=0.001)\n",
    "                    \n",
    "                    print(\"Cluster Plotting done. Continuing\")\n",
    "                    \n",
    "                    # map Pointcloud to Cameragrid\n",
    "                    i=0\n",
    "                    \"\"\"\n",
    "                    while i < cluster_scene.shape[0]:\n",
    "                        \n",
    "                    \n",
    "                        depth_point = [cluster_scene.points.x[i] , cluster_scene.points.y[i],cluster_scene.points.z[i]]\n",
    "                        color_pixel[i] = rs.rs2_project_point_to_pixel(color_intrinsics, depth_point)\n",
    "                        print(\"color pixel\", color_pixel)\n",
    "                    \"\"\"\n",
    "                    state.paused = False\n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "                except:\n",
    "                    print(\"error\")\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break\n",
    "                    pipeline.stop()\n",
    "\n",
    "                    \n",
    "                \n",
    "                \n",
    "\n",
    "        # Render\n",
    "        now = time.time()\n",
    "\n",
    "        out.fill(0)\n",
    "\n",
    "        grid(out, (0, 0.5, 1), size=1, n=10)\n",
    "        frustum(out, depth_intrinsics)\n",
    "        axes(out, view([0, 0, 0]), state.rotation, size=0.1, thickness=1)\n",
    "\n",
    "        if not state.scale or out.shape[:2] == (h, w):\n",
    "            pointcloud(out, verts, texcoords, color_source)\n",
    "        else:\n",
    "            tmp = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "            pointcloud(tmp, verts, texcoords, color_source)\n",
    "            tmp = cv2.resize(\n",
    "                tmp, out.shape[:2][::-1], interpolation=cv2.INTER_NEAREST)\n",
    "            np.putmask(out, tmp > 0, tmp)\n",
    "\n",
    "        if any(state.mouse_btns):\n",
    "            axes(out, view(state.pivot), state.rotation, thickness=4)\n",
    "\n",
    "        dt = time.time() - now\n",
    "\n",
    "        cv2.setWindowTitle(\n",
    "            state.WIN_NAME, \"RealSense (%dx%d) %dFPS (%.2fms) %s\" %\n",
    "            (w, h, 1.0/dt, dt*1000, \"PAUSED\" if state.paused else \"\"))\n",
    "        \n",
    "        #  ----------------------------------- cv2 Output -----------------------------------------------\n",
    "        #if state.segmentation:\n",
    "        #    segmentationstream = np.hstack((out, pointcloud))\n",
    "        #    cv2.imshow(state.WIN_NAME, segmentationstream)\n",
    "        #    key = cv2.waitKey(1)\n",
    "            \n",
    "        #elsee\n",
    "        \n",
    "        colorstream = np.hstack((out, color_image))\n",
    "        \n",
    "        cv2.imshow(state.WIN_NAME, colorstream)\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == ord(\"x\"): # Segmentation\n",
    "            state.segmentation ^= True\n",
    "            \n",
    "        if key == ord(\"r\"):\n",
    "            state.reset()\n",
    "\n",
    "        if key == ord(\"p\"):\n",
    "            state.paused ^= True\n",
    "\n",
    "        if key == ord(\"d\"):\n",
    "            state.decimate = (state.decimate + 1) % 3\n",
    "            decimate.set_option(rs.option.filter_magnitude, 2 ** state.decimate)\n",
    "            print(\"decimation at\", state.decimate)\n",
    " \n",
    "        if key == ord(\"4\"):\n",
    "            state.minthreshold = (state.minthreshold + 0.1)\n",
    "            threshold_filter.set_option(rs.option.min_distance, state.minthreshold)\n",
    "            print(\"min threshold at\", state.minthreshold)\n",
    "            \n",
    "        if key == ord(\"5\"):\n",
    "            state.maxthreshold = (state.maxthreshold - 0.1)\n",
    "            threshold_filter.set_option(rs.option.max_distance, state.maxthreshold)\n",
    "            print(\"max threshold at\", state.maxthreshold)\n",
    "\n",
    "        \n",
    "        if key == ord(\"3\"):\n",
    "            state.threshold ^= True\n",
    "            \n",
    "        if key == ord(\"1\"):            \n",
    "            state.spatial ^= True\n",
    "            \n",
    "        if key == ord(\"2\"):\n",
    "            state.holefilling ^= True\n",
    "            \n",
    "        if key == ord(\"z\"):\n",
    "            state.scale ^= True\n",
    "\n",
    "        if key == ord(\"c\"):\n",
    "            state.color ^= True\n",
    "\n",
    "        if key == ord(\"s\"):\n",
    "            cv2.imwrite('./out.png', out)\n",
    "\n",
    "        if key == ord(\"e\"):\n",
    "            points.export_to_ply('./out.ply', mapped_frame)\n",
    "\n",
    "        if key in (27, ord(\"q\")) or cv2.getWindowProperty(state.WIN_NAME, cv2.WND_PROP_AUTOSIZE) < 0:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    except:\n",
    "        break\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"An Error occured. Stopping everything\")\n",
    "        pipeline.stop()\n",
    "            \n",
    "# Stop streaming\n",
    "pipeline.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voxelscene.plot(d=3, mode=\"density\", cmap=\"hsv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pointcloud to 2D Camera Grid\n",
    "\n",
    "pixel_clusterscene = np.empty((0,2))\n",
    "\n",
    "i=0\n",
    "k=0\n",
    "while i < cluster_scene.xyz.shape[0]:\n",
    "\n",
    "\n",
    "    depth_point = [cluster_scene.points.x[i], cluster_scene.points.y[i],cluster_scene.points.z[i]]\n",
    "\n",
    "    color_point = rs.rs2_transform_point_to_point(depth_to_color_extrin, depth_point)\n",
    "    color_pixel = rs.rs2_project_point_to_pixel(color_intrinsics, color_point)\n",
    "    \n",
    "    pixel_clusterscene = np.vstack((pixel_clusterscene, color_pixel))\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "pixel_clusterscene = np.around(pixel_clusterscene)\n",
    "pixel_clusterscene = pixel_clusterscene.astype(int)\n",
    "print(\"color pixel\", pixel_clusterscene.shape)\n",
    "\n",
    "\n",
    "x_values = np.array((1,1), dtype = int)\n",
    "y_values = np.array((1,1), dtype = int)\n",
    "\n",
    "i=0\n",
    "for points in pixel_clusterscene:\n",
    "    x_values = np.concatenate((x_values, points[0]), axis=None)\n",
    "\n",
    "    y_values = np.concatenate((y_values, points[1]), axis=None)\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "x_max = np.max(x_values) +1\n",
    "y_max = np.max(y_values) +1\n",
    "print(x_max,y_max)\n",
    "\n",
    "\n",
    "# Mapping \n",
    "final_clusterscene = np.zeros((x_max, y_max), dtype = int)\n",
    "\n",
    "for points in pixel_clusterscene:\n",
    "    final_clusterscene[points[0]][points[1]] = 255\n",
    "\n",
    "np.save(\"pixel_clusterscene\",final_clusterscene)\n",
    "\n",
    "\n",
    "#cv2.imshow(\"test\", final_clusterscene) \n",
    "#key = cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "a = np.load(\"pixel_clusterscene.npy\")\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testfall aufbauen:\n",
    "\n",
    "3D CNN gegen 2D CNN stärken und schwächen. Verbinden mit Robot Vision oder Augmented Reality\n",
    "\n",
    "Verschiedene Belichtungen \n",
    "\n",
    "Verdeckungen\n",
    "\n",
    "\n",
    "\n",
    "Limitationen:\n",
    "Datensatz\n",
    "Parameter Netzwerk\n",
    "\n",
    "\n",
    "\n",
    ".object file erstellen von jedem segment ->  Import to Unity3dVR\n",
    "\n",
    "ziel:\n",
    "\n",
    "automatsche segmentation für scenen in VR\n",
    "\n",
    "besser als händische segmentation in unity z.b\n",
    "\n",
    "\n",
    "warum besser als sematic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"test\", a) \n",
    "key = cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load RealSense .PLY Data to PyntCloud Object\n",
    "pointcloud = PyntCloud.from_file(\"out.ply\") \n",
    "#pointcloud = pointcloud.get_sample(\"mesh_random\", n=50000, rgb=True, normals=False, as_PyntCloud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = pointcloud.plot(initial_point_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------ Voxilisation -----------------------------------------------------\n",
    "\n",
    "# create Voxelgrid from Pointcloudscene\n",
    "voxelgrid_id = pointcloud.add_structure(\"voxelgrid\", n_x=128, n_y=128, n_z=128)\n",
    "voxelscene = pointcloud.structures[voxelgrid_id]\n",
    "\n",
    "# Create binary array from Voxelscene \n",
    "binary_voxelscene = voxelscene.get_feature_vector(mode=\"binary\")\n",
    "\n",
    "voxelscene.plot(d=3, mode=\"density\", cmap=\"hsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Network input\n",
    "binary_voxelscene = np.expand_dims(binary_voxelscene, axis=0)\n",
    "print(binary_voxelscene.shape)\n",
    "\n",
    "# Classification Output on Testvoxels\n",
    "cnn_out = model.predict(binary_voxelscene)\n",
    "\n",
    "cnn_prediction = np.argmax(cnn_out)\n",
    "\n",
    "print(\"Predicted Numbers of Objects:\", cnn_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------- K Means Clustering --------------------------------------------------\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = cnn_prediction, init='k-means++')\n",
    "\n",
    "#pointcloud = pointcloud.xyz\n",
    "\n",
    "kmeans = kmeans.fit(pointcloud)\n",
    "labels = kmeans.predict(pointcloud)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "pe = ax.scatter(pointcloud[:, 0], pointcloud[:, 1], pointcloud[:, 2], c=labels, cmap='viridis',\n",
    "            edgecolor='k', s=3, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------- Evaluation of Clustering ----------------------------------------------------\n",
    "\n",
    "clusters_dict = {i: pointcloud[np.where(labels == i)[0]] for i in range(kmeans.n_clusters)}\n",
    "\n",
    "#  dictionary to list \n",
    "clusters_list = []\n",
    "for key, value in clusters_dict.items():\n",
    "    temp = [key,value]\n",
    "    clusters_list.append(temp)\n",
    "    \n",
    "# Plotten der einzelnen Cluster    \n",
    "for i in range(kmeans.n_clusters):\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter(clusters_dict[i][:,0], clusters_dict[i][:, 1], clusters_dict[i][:, 2], \n",
    "               cmap='viridis',edgecolor='k', s=1, alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------  Verteilung der Punkte/Cluster zu Punkte/Original PC -------------------------------------------\n",
    "\n",
    "c = 0   # Counter for Clusters\n",
    "p = 0   # Counter for Pointclouds\n",
    "counter = 0     # Counter for matches between Pointclouds and Clusters\n",
    "allocation_list = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "''' \n",
    "Structure of allocation list\n",
    "\n",
    "    p0  p1  p2 ...\n",
    "c0\n",
    "c1 \n",
    "c2\n",
    "...\n",
    "'''\n",
    "\n",
    "while c < 3:\n",
    "\n",
    "    for Pj in clusters_dict[c]:\n",
    "        for Pi in labeled_pointcloudscene[p]:\n",
    "            if np.all(Pj == Pi):\n",
    "                counter = counter + 1\n",
    "\n",
    "    allocation_list[c, p] = counter\n",
    "    p = p + 1\n",
    "    counter = 0\n",
    "\n",
    "    if p > cnn_prediction:  # max anzahl an pointclouds rounded_cnn\n",
    "        c = c + 1\n",
    "        p = 0\n",
    "    else:\n",
    "       continue\n",
    "\n",
    "print(allocation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocation_max = np.amax(allocation_list, axis=1)\n",
    "x = 0\n",
    "y = 0\n",
    "allocation_result={}\n",
    "\n",
    "'''\n",
    "    returns allocation between Clusters/ PClouds like: (Clusternumber,Pointcloudnumber), ...\n",
    "    --> Prediction based of where is the max Value \n",
    "'''\n",
    "\n",
    "while y <= (len(allocation_max) - 1):  # len q = 3 but we start at 0 \n",
    "    \n",
    "    result = (np.where(allocation_list[y] == allocation_max[y]))\n",
    "    allocation_result[y] =  y , result[0][0]\n",
    "    print(\"Cluster\",y,\"belongs to\", \"Pointcloud\",result[0][0])\n",
    "    y = y + 1 \n",
    "\n",
    "allocation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "score = {}\n",
    "temp = 0\n",
    "max_value = np.amax(allocation_list)\n",
    "\n",
    "# Calculates for every existing Cluster the score\n",
    "while i <= 2:\n",
    "    for d in allocation_list[i]:  \n",
    "        if (d > 0) and (d < allocation_max[i]):  # d > 0 < clusters maxvalue\n",
    "            temp = 0\n",
    "            temp = temp + d\n",
    "        elif (d > 0) and (d < max_value): # d > 0 < overall max value in allocation list\n",
    "            temp = 0\n",
    "            temp = temp + (max_value - d)\n",
    "        score[i] = temp\n",
    "    print(\"Cluster\",i, \"score=\", score[i])\n",
    "\n",
    "    i = i + 1\n",
    "    \n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
