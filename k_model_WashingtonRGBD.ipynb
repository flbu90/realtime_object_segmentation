{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model mit Pointcloud manipulationen und dem Washington RGBD Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo:\n",
    "\n",
    "\n",
    "Umgebungsnoise !!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Version updated: 07.08.2019 (latest version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyntcloud import PyntCloud\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint, uniform\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "#from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Visualize the test data\n",
    "import scipy.io as io\n",
    "import scipy.ndimage as nd\n",
    "\n",
    "# ---------------------------------------------- Variables -------------------------------------------------------------\n",
    "\n",
    "DATADIR = \"data/washington_rgbd_dataset/\"\n",
    "CATEGORIES = [\"apple\", \"coffee_mug\", \"greens\", \"onion\", \"soda_can\", \"ball\", \"comb\", \"hand_towel\", \"orange\", \"sponge\",\n",
    "              \"banana\", \"dry_battery\", \"instant_noodles\", \"peach\", \"stapler\", \"bell_pepper\", \"flashlight\", \"keyboard\",\n",
    "              \"pear\", \"tomato\", \"binder\", \"food_bag\", \"kleenex\", \"pitcher\", \"toothbrush\", \"bowl\", \"food_box\", \"lemon\",\n",
    "              \"plate\", \"toothpaste\", \"calculator\", \"food_can\", \"lightbulb\", \"pliers\", \"water_bottle\", \"camera\", \n",
    "              \"food_cup\", \"lime\", \"potato\", \"cap\", \"food_jar\", \"marker\", \"rubber_eraser\", \"cell_phone\", \"garlic\",\n",
    "              \"mushroom\", \"scissors\", \"cereal_box\", \"glue_stick\", \"notebook\", \"shampoo\"] # 51 Cats\n",
    "r = 0 \n",
    "\n",
    "# max(X,Y,Z) of Pointcloud\n",
    "pX_max = 0\n",
    "pY_max = 0\n",
    "pZ_max = 0\n",
    "\n",
    "# Scene Container creating the Batches for Traning\n",
    "scene_container_x = {}\n",
    "scene_container_y = {}\n",
    "\n",
    "# dict for evaluating past losses\n",
    "loss_dict = []\n",
    "# Counter on how many scenes the Network has been trained\n",
    "counter_trainingobjects = 0\n",
    "\n",
    "# Number of Scenes for Batch-Training\n",
    "number_scenes = 32\n",
    "\n",
    "# ---------------------------------------------- Functions/Classes ----------------------------------------------------\n",
    "\n",
    "\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "\n",
    "def switch_pos(argument):\n",
    "    \"\"\"Switcher for positional change of PCD in the scene\"\"\"\n",
    "    pos1 = uniform(0,1)\n",
    "    pos2 = uniform(1.1,2)\n",
    "    pos3 = uniform(2.1,3)\n",
    "    pos4 = uniform(3.1,4)\n",
    "    pos5 = uniform(4.1,5)\n",
    "    pos6 = uniform(5.1,6)\n",
    "    pos7 = uniform(6.1,7)\n",
    "    pos8 = uniform(7.1,8)\n",
    "\n",
    "    switcher = {\n",
    "        0: (pos1, pos6, pos7),\n",
    "        1: (pos2, pos4, pos6),\n",
    "        2: (pos3, pos2, pos5),\n",
    "        3: (pos4, pos7, pos1),\n",
    "        4: (pos5, pos3, pos2),\n",
    "        5: (pos6, pos5, pos6),\n",
    "        6: (pos8, pos1, pos8)\n",
    "    }\n",
    "\n",
    "    return switcher.get(argument, \"nothing\")\n",
    "\n",
    "def pc_normalize(pointcloud):\n",
    "    \n",
    "    l = pointcloud.shape[0]\n",
    "    centroid = np.mean(pointcloud, axis=0)\n",
    "    pointcloud = pointcloud - centroid\n",
    "    m = np.max(np.sqrt(np.sum(pointcloud**2, axis=1)))\n",
    "    pointcloud = pointcloud / m\n",
    "    return pointcloud\n",
    "\n",
    "\n",
    "# --------------------------------------------- Network Setup ---------------------------------------------------------\n",
    "\n",
    "\n",
    "# To activate type in console \"tensorboard --logdir=logs/\" and then start training and open link from consoleinput\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((128, 128, 128, 1), input_shape=(128, 128, 128)),  # Add 1 dim for 3D CNN\n",
    "    tf.keras.layers.Conv3D(filters=32, kernel_size=(3,3,3), strides=2, activation='relu'),\n",
    "    tf.keras.layers.Conv3D(filters=64, kernel_size=(3,3,3), strides=2, activation='relu'),\n",
    "    tf.keras.layers.Conv3D(filters=128, kernel_size=(3,3,3), strides=2, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -------------------------------------Begin Create Pointcloudscene --------- ------------------------------------------\n",
    "\n",
    "# Main-Loop for Training till User interruption\n",
    "while True: \n",
    "    \n",
    "    try: \n",
    "        # Loop iteration\n",
    "        v = 0  # Till number of Scene in Scene Container\n",
    "\n",
    "        while v < number_scenes: # Adds Scenes to the Scene Container\n",
    "\n",
    "            # Creates an empty Pointcloud Scene\n",
    "            pointcloudscene = np.empty((0, 3), dtype=float)\n",
    "\n",
    "            # How many Objects per Scene\n",
    "            number_objects = randint(2, 7)\n",
    "            #print(number_objects)\n",
    "\n",
    "            # Loop iterations\n",
    "            i = 0  # Number of pointcloud per Scene\n",
    "            y = 0  # Randomn Object in datapath\n",
    "\n",
    "            while i < number_objects:  # Number of Pointcloud per scene\n",
    "\n",
    "                working_category = CATEGORIES[randint(0, 50)] # What Category is selected\n",
    "\n",
    "                path = os.path.join(DATADIR, working_category) # for 51 Categories\n",
    "                #number_folder = len(next(os.walk(path))[1]) # Number of Folders in Category            \n",
    "\n",
    "                #path = path + \"/\" + working_category + \"_\" + str(randint(1, number_folder)) # Add random folder to path\n",
    "\n",
    "                path = path + \"/\" + random.choice(os.listdir(path))\n",
    "\n",
    "                #files = next(os.walk(path))[2]\n",
    "                #number_files = len(files) # Number of pcd files in randomly selected Category\n",
    "                #print(\"nb files\", number_files)\n",
    "\n",
    "                path = path + \"/\" + random.choice(os.listdir(path)) # Picks Randomn File from path\n",
    "                #print(path)\n",
    "\n",
    "                # Load ModelNet10 Data to PyntCloud Object\n",
    "                pointcloud = PyntCloud.from_file(path)\n",
    "\n",
    "\n",
    "\n",
    "                #df_pointcloud = pd.DataFrame(pointcloud.points)\n",
    "                #del df_pointcloud['imX']\n",
    "                #del df_pointcloud['imY']\n",
    "                #del df_pointcloud['red']\n",
    "                #del df_pointcloud['green']\n",
    "                #del df_pointcloud['blue']\n",
    "                #print(df_pointcloud)\n",
    "\n",
    "\n",
    "                #pointcloud = PyntCloud(df_pointcloud)\n",
    "                #pointcloud = pointcloud.get_sample(\"mesh_random\", n=10000, rgb=False, normals=False, as_PyntCloud=False) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # ------------------------------- Pointcloud manipulations ------------------------------------------------#\n",
    "\n",
    "                #Pointcloud Normaliazation\n",
    "\n",
    "                pointcloud = pointcloud.xyz\n",
    "                normalized_pointcloud = pc_normalize(pointcloud)\n",
    "\n",
    "                p_x = normalized_pointcloud[:, 0]\n",
    "                p_y = normalized_pointcloud[:, 1]\n",
    "                p_z = normalized_pointcloud[:, 2]\n",
    "\n",
    "                normalized_pointcloud = pd.DataFrame(zip(p_x, p_y, p_z), columns=['x', 'y', 'z'])\n",
    "                normalized_pointcloud = PyntCloud(normalized_pointcloud)\n",
    "\n",
    "                # Add Noise to each Pointcloud\n",
    "                noise = pd.DataFrame(np.random.uniform(0.0,0.2,[len(normalized_pointcloud.points.x),3]),columns=['x','y','z'])\n",
    "                noisy_pointcloud = normalized_pointcloud.points.add(noise)\n",
    "                noisy_pointcloud = PyntCloud(noisy_pointcloud)\n",
    "\n",
    "                # Change Position of Pointcloud \n",
    "                pos = switch_pos(i)\n",
    "                final_pointcloud = noisy_pointcloud.xyz + ([pos])\n",
    "\n",
    "                # Append Pointcloud to Scene\n",
    "                pointcloudscene = np.append(pointcloudscene, final_pointcloud, axis=0)\n",
    "\n",
    "                # Create Labeled Pointcloudscene for allocation Pointclouds with clusters\n",
    "                #labeled_pointcloudscene.update({i: npy_cloud})\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "            # Create pandas dateframe to convert scene back to pyntcloud Object\n",
    "            p_x = pointcloudscene[:, 0]\n",
    "            p_y = pointcloudscene[:, 1]\n",
    "            p_z = pointcloudscene[:, 2]\n",
    "\n",
    "            df_pointcloudscene = pd.DataFrame(zip(p_x, p_y, p_z), columns=['x', 'y', 'z'])\n",
    "            pyntcloud_scene = PyntCloud(df_pointcloudscene)\n",
    "\n",
    "\n",
    "            # ------------------------------------------ Voxilisation -----------------------------------------------------\n",
    "\n",
    "            # create Voxelgrid from Pointcloudscene\n",
    "            voxelgrid_id = pyntcloud_scene.add_structure(\"voxelgrid\", n_x=128, n_y=128, n_z=128)\n",
    "            voxelscene = pyntcloud_scene.structures[voxelgrid_id]\n",
    "\n",
    "            # Create binary array from Voxelscene \n",
    "            binary_voxelscene = voxelscene.get_feature_vector(mode=\"binary\")\n",
    "\n",
    "            # Create a Voxelscene Container of Scenes\n",
    "            scene_container_x[v]=binary_voxelscene\n",
    "            scene_container_y[v]=number_objects\n",
    "\n",
    "            v = v + 1\n",
    "\n",
    "        v = 0\n",
    "\n",
    "        #---------------------------------------- Prepare data for Network input ------------------------------------------\n",
    "\n",
    "        # X = datainput for Network\n",
    "        X = np.zeros((number_scenes,128,128,128), dtype=float) \n",
    "        k = 0\n",
    "\n",
    "        for key, value in scene_container_x.items():\n",
    "            temp = [value]\n",
    "            X[k] = np.concatenate(temp)\n",
    "            k = k + 1\n",
    "\n",
    "        # Y = label input for Network\n",
    "        Y = []\n",
    "        for key, value in scene_container_y.items():\n",
    "            temp = [value]\n",
    "            Y.append(temp)\n",
    "        Y = np.asarray(Y)\n",
    "        Y = tf.keras.utils.to_categorical(Y, 10)\n",
    "\n",
    "        # --------------------- Training the Network by incrementally call fit function ------------------------------------\n",
    "\n",
    "        history = LossHistory()\n",
    "        model.fit(X, Y, batch_size=8, epochs=1, verbose=1, callbacks=[tensorboard, history])\n",
    "        counter_trainingobjects = counter_trainingobjects + 1\n",
    "\n",
    "        if (history.losses[0] < 0.001):\n",
    "            model.save('savedmodel/k_model_CNN.h5')\n",
    "            print(\"Model has been saved and trained on\", counter_trainingobjects*32, \"Voxelscenes\")\n",
    "   \n",
    "    except: continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
